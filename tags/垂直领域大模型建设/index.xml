<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>垂直领域大模型建设 on 张子彪的博客</title>
        <link>https://zhangzib123.github.io/tags/%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BB%BA%E8%AE%BE/</link>
        <description>Recent content in 垂直领域大模型建设 on 张子彪的博客</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Mon, 04 Aug 2025 11:13:06 +0800</lastBuildDate><atom:link href="https://zhangzib123.github.io/tags/%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BB%BA%E8%AE%BE/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>垂直领域大模型建设经验总结</title>
        <link>https://zhangzib123.github.io/p/%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BB%BA%E8%AE%BE%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/</link>
        <pubDate>Mon, 04 Aug 2025 11:13:06 +0800</pubDate>
        
        <guid>https://zhangzib123.github.io/p/%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BB%BA%E8%AE%BE%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/</guid>
        <description>&lt;h2 id=&#34;垂直领域大模型建设经验总结&#34;&gt;垂直领域大模型建设经验总结
&lt;/h2&gt;&lt;h3 id=&#34;建设成果&#34;&gt;建设成果
&lt;/h3&gt;&lt;p&gt;通过预训练和微调构建国资国企知识领域大模型，我公司AI团队，从2024年到2025上半年，进行了两轮的垂直领域训练，评测指标已实现对基座模型的超越，能够满足用户需求，总体情况如下：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;维度&lt;/th&gt;
          &lt;th&gt;第一轮训练&lt;/th&gt;
          &lt;th&gt;第二轮训练&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;基座模型&lt;/td&gt;
          &lt;td&gt;Qwen1.5-7B&lt;/td&gt;
          &lt;td&gt;Qwen2.5-72B&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;预训练语料规模&lt;/td&gt;
          &lt;td&gt;约195亿tokens（gpt tokenizer）&lt;/td&gt;
          &lt;td&gt;约17亿tokens （qwen2.5 tokenizer）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;领域微调语料（问答对数量）&lt;/td&gt;
          &lt;td&gt;23144&lt;/td&gt;
          &lt;td&gt;397355&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;覆盖领域任务&lt;/td&gt;
          &lt;td&gt;领域问答、分类任务&lt;/td&gt;
          &lt;td&gt;领域问答、报告生成&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;模型上下文长度&lt;/td&gt;
          &lt;td&gt;2048&lt;/td&gt;
          &lt;td&gt;8192&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;训练方式&lt;/td&gt;
          &lt;td&gt;预训练+领域SFT&lt;/td&gt;
          &lt;td&gt;预训练+通用SFT+领域SFT&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;核心任务指标对比（ROUGE）&lt;/td&gt;
          &lt;td&gt;领域问答超基座模型6% 分类任务超基座模型50%&lt;/td&gt;
          &lt;td&gt;领域问答超基座模型14% 报告生成任务超基座模型0.65%&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;存在问题&lt;/td&gt;
          &lt;td&gt;回答内容简短，难以满足复杂场景需求。&lt;/td&gt;
          &lt;td&gt;生成内容重复，回答仍偏短，对超长上下文理解存在缺陷。&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;在国资国企领域数据集上的评测指标已实现对基座模型的超越，领域问答能力优于DeepSeek、豆包大模型。不过，写作任务能力需强化；且模型当前关键短板集中在：内容生成时回答偏短，长文本及上下文理解也未达理想状态，这些将是后续优化的核心方向。&lt;/p&gt;
&lt;h3 id=&#34;后续计划&#34;&gt;后续计划
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;根据存在的问题以及涉及到的专业语料的数量研判，下一步预训练及微调方向&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1、语料需求&lt;/p&gt;
&lt;p&gt;• 核心语料：10GB+内部资料
• 辅助语料：5GB+领域相关语料
• 微调语料：基础问答5万对问答对&lt;/p&gt;
&lt;p&gt;深度分析15万对问答对&lt;/p&gt;
&lt;p&gt;写作任务25万对问答对&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;基座模型选择&lt;/p&gt;
&lt;p&gt;Qwen3-32B&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;预训练方法&lt;/p&gt;
&lt;p&gt;参数高效方法（Lora）&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        
    </channel>
</rss>
