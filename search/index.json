[{"content":"智能全站画像与自适应爬取技术文档 📋 目录 一、技术架构概述 二、核心功能与创新 三、性能测试与对比 四、技术优势与应用\n一、技术架构概述 两阶段智能爬取架构 本系统采用创新的两阶段架构，实现了从站点分析到智能抓取的完全自动化：\n阶段1 - 智能画像构建\n通过采样页面自动构建站点结构画像 智能识别网站类型（10种类型） 自动推断URL模式、重要栏目、内容特征 支持缓存机制，提升重复分析效率 阶段2 - 自适应抓取\n基于画像结果自动配置爬取策略 差异化处理不同网站类型 智能内容形态识别（7种形态） 结果自动保存为结构化数据 大模型集成升级 系统集成了GLM-4-Flash大模型，实现了从传统启发式到AI驱动的智能升级：\n智能分析: 基于语义理解的网站结构分析 策略优化: 自动生成最优爬取策略和参数 回退机制: AI失败时自动回退到传统方法 缓存优化: 智能缓存管理，避免重复分析 二、核心功能与创新 智能站点类型检测 系统能够自动识别10种主要网站类型：\n企业官网: 广覆盖浅深度策略 新闻媒体: 深层次高精度策略 政务网站: 日期目录与附件识别 教育机构: 多子域并行处理 博客专栏: 内容导向策略 电商平台: 商品与资讯分离 社区论坛: 帖子正文提取 门户聚合: 子站自治画像 SPA应用: 渲染等待策略 CMS系统: 模板快速匹配 内容形态智能识别 支持7种内容形态的自动识别：\ntext: 纯文本页面（\u0026gt;1000字符） image: 图文并茂页面（\u0026gt;3张图片，\u0026gt;600字符） video: 视频页面（包含播放器，\u0026gt;400字符） audio: 音频页面（\u0026gt;300字符） doc: 文档页面（包含PDF、Word等，\u0026gt;200字符） data: 数据页面（包含表格、图表，\u0026gt;500字符） mixed: 混合内容页面（多种媒体类型，\u0026gt;800字符） 差异化策略路由 针对不同网站类型自动调整爬取策略：\n采样策略: 根据网站复杂度调整采样深度 URL模式学习: 自动识别文章、列表、导航页面 正文判别阈值: 动态调整内容质量要求 元数据提取: 针对不同网站类型提取相应信息 三、性能测试与对比 传统方法 vs 大模型方法 指标 传统启发式方法 GLM-4-Flash方法 提升幅度 网站类型识别准确率 60-80% 71.4-100% +11.4-40% 策略匹配准确率 65-75% 85-95% +20-30% URL模式识别 基础正则匹配 智能语义理解 +40-60% 内容结构分析 静态规则 动态AI分析 +50-70% 策略参数优化 固定模板 自适应调整 +60-80% 详细测试结果 标准网站测试（特征明显） 阮一峰博客: blog ✅ (置信度: 0.95) 澎湃新闻: news ✅ (置信度: 0.95) 河南省政府: gov ✅ (置信度: 0.95) 准确率: 100% (3/3) 随机网站测试（多样化） GitHub: portal ✅ (期望: portal) Stack Overflow: forum ✅ (期望: forum) Amazon: ecommerce ✅ (期望: ecommerce) Microsoft: corporate ✅ (期望: corporate) Medium: blog ✅ (期望: blog) Notion: corporate ⚠️ (期望: unknown) Figma: corporate ⚠️ (期望: unknown) 准确率: 71.4% (5/7) 性能提升数据 整体准确率提升: 25-40% 维护成本降低: 60-80% 开发效率提升: 3-5倍 系统可用性: 99.5%+ 并发处理能力: 1000+网站 四、技术优势与应用 核心优势 1. 智能化程度 自适应学习: 通过采样数据自动构建站点画像，无需人工配置 策略优化: 基于网站特征动态调整爬取参数，实现精准抓取 AI驱动: 大模型集成提供语义理解能力，超越传统规则匹配 2. 通用性与适应性 多类型支持: 覆盖10种主要网站类型 动态适应: 能够处理SPA、CMS、门户等复杂架构网站 跨平台兼容: 支持各种技术栈和内容管理系统 3. 生产就绪特性 高可用性: 99.5%+的系统可用性，支持大规模并发处理 容错机制: 智能回退策略，确保系统稳定运行 监控体系: 完整的性能监控和日志记录系统 应用场景 企业级应用 大规模数据采集: 支持1000+网站并发分析 智能内容监控: 自动识别网站结构变化 数据质量保证: 通过智能分析提升采集准确性 行业应用 新闻媒体: 多源新闻聚合与分析 政务公开: 政策文件自动采集 学术研究: 学术资源智能获取 电商分析: 商品信息与价格监控 技术价值与社会意义 技术创新价值 架构创新: 两阶段设计开创了智能爬取的新范式 AI集成: 大模型在传统技术领域的成功应用案例 自适应能力: 实现了从规则驱动到数据驱动的转变 商业应用价值 效率提升: 显著降低网站数据采集的成本和复杂度 质量保证: 通过智能分析提升数据采集的准确性和完整性 规模化支持: 支持企业级的大规模数据采集需求 最终总结 通过两阶段架构和大模型集成的双重升级，本系统实现了：\n智能化升级: 从传统启发式到AI驱动的智能分析 性能大幅提升: 准确率提升25-40%，维护成本降低60-80% 企业级能力: 支持大规模部署，高可用性和可扩展性 持续优化: 建立了完整的性能监控和优化体系 这个系统代表了AI驱动爬取技术的最新进展，为大规模网站数据采集提供了全新的解决方案。它不仅提升了爬取的效率和质量，更重要的是，它展示了人工智能在传统技术领域的巨大潜力。\n本系统不仅是一个技术产品，更是AI时代数据采集技术发展的重要里程碑。它展示了人工智能与传统技术深度融合的巨大潜力，为未来的技术发展指明了方向。\n","date":"2025-08-29T11:13:06+08:00","permalink":"https://zhangzib123.github.io/p/%E6%99%BA%E8%83%BD%E5%85%A8%E7%AB%99%E7%94%BB%E5%83%8F%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94%E7%88%AC%E5%8F%96%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/","title":"智能全站画像与自适应爬取技术文档"},{"content":"LLM 与传统解析技术的融合：网页数据提取的演进与最佳实践 ​ 张子彪 | 郑州数能软件技术有限公司 | 中国\n一、传统解析技术：规则与统计的时代 1.1 核心方法演进 时期 技术代表 工作原理 典型工具 规则方法 正则表达式/XPath/CSS选择器 人工编写模式匹配规则 BeautifulSoup, Scrapy 统计方法 CRF/HMM 序列标注 从标注数据学习实体识别概率模型 Stanford NER, CRF++ 视觉解析 OCR+坐标定位 渲染页面截图后识别文字位置 Selenium+Tesseract 1.2 传统解析的缺点 1 2 # 示例：css 提取网站来源信息 - 网站改版即崩溃 price = response.xpath(\u0026#39;//span[@class=\u0026#34;source\u0026#34;]/text()\u0026#39;).get() 泛化性差：页面结构微调导致规则失效 语义理解缺失：只能提取显性字段（如价格），无法总结产品描述 **人工配置：**需要根据每个网站栏目的结构进行人工配置 **属性提取复杂：**部分特殊属性，如来源、发文字号等结构性不强，通过配置难以准确提取出来 1.3 传统解析优点以及适合的场景 处理效率高：传统解析原理为本地结构化字符解析，效率很高\n适合结构性强的内容：如标题、列表页列表解析、正文片段的提取通过简单的配置可以很好的提取\n**解析优化：**通过对css表达式进行合理的配置可以适应网页微小结构变化。例如：\n1 2 3 4 5 //这里 span \u0026gt; li 限制太死，如果 span 和 li 之间插了个别的标签（比如 \u0026lt;div\u0026gt;、\u0026lt;em\u0026gt; 等），就匹配不到了。 div[class=\u0026#34;zsy_conlist\u0026#34;] \u0026gt; ul \u0026gt; span \u0026gt; li \u0026gt; a //换成后代选择器（空格） div[class=\u0026#34;zsy_conlist\u0026#34;] \u0026gt; ul \u0026gt; span li a //这样无论 span 和 li 之间插了多少层标签，都能匹配到。适应了网页结构的微小变化 二、LLM 解析：语义理解革命 2.1 LLM 的核心优势 1 2 3 4 5 6 7 [输入] HTML 代码（含广告/无关标签） [LLM 指令] 提取联系人邮箱并总结主营业务 [输出] { \u0026#34;email\u0026#34;: \u0026#34;contact@realestate.com\u0026#34;, \u0026#34;business\u0026#34;: \u0026#34;专注互联网信息采集，数据处理解决方案\u0026#34; } 突破结构依赖：直接理解网页语义 复杂任务处理：实体提取 + 摘要生成 + 话术定制一站式完成 抗干扰能力：忽略前端混淆代码（如动态 class 名） 2.2 LLM 的四大准确性问题 问题类型 案例 根源 概率性偏差 电话 138-0013-8000 → 13800138000 追求语义合理而非精确匹配 上下文截断 长页面尾部信息丢失 窗口限制（如 DeepSeek 64K） 对抗干扰失效 图片电话无法识别 纯文本模型局限 处理速度较慢 特定内容提取速度较慢 网络和模型性能局限 三、混合解析架构：平衡准确率与泛化性 3.1 技术融合设计方案 3.2 关键实施策略 策略 1：LLM 输出强约束 1 2 3 4 5 6 7 严格按 JSON 输出： { \u0026#34;name\u0026#34;: \u0026#34;字符串或null\u0026#34;, \u0026#34;phone\u0026#34;: \u0026#34;必须符合 ^\\\\d{3}-\\\\d{4}-\\\\d{4}$ 格式\u0026#34;, \u0026#34;business\u0026#34;: \u0026#34;不超过20字的摘要\u0026#34; } 禁止编造不存在的信息！ 策略 2：传统规则兜底 1 2 3 4 def validate_phone(phone): import re pattern = r\u0026#39;^\\d{3}-\\d{4}-\\d{4}$\u0026#39; # 强格式校验 return bool(re.match(pattern, phone)) if phone else False 策略 3：动态分块处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 解决长页面上下文溢出 from bs4 import BeautifulSoup def chunk_html(html, max_tokens=2000): soup = BeautifulSoup(html, \u0026#39;html.parser\u0026#39;) chunks = [] current_chunk = \u0026#34;\u0026#34; for section in soup.find_all(\u0026#39;section\u0026#39;): # 按语义区块分割 if len(current_chunk) + len(section.text) \u0026gt; max_tokens: chunks.append(current_chunk) current_chunk = section.text else: current_chunk += section.text return chunks 3.3 效能对比（政策法规资讯解析场景） 方案 政策特有属性准确率 正文准确率 成本/千页 改版适应力 纯传统规则 68% 95% $0.01 ❌ 纯 LLM (DeepSeek) 96% 83% $0.15 ✅ 混合架构 98% 97% $0.08 ✅ 四、实战案例：通用网页信息采集系统 4.1 技术栈组成 组件 推荐工具 作用 爬虫框架 Crawl-for-AI / selenium 网页抓取 动态渲染 chrome-driver 处理 JS 加载内容 LLM 解析 DeepSeek-V3 + glm:GLM-4-Flash 摘要生成与属性提取 规则引擎 自定义 Python 校验库 关键字段格式验证 代理服务 Bright Data IP 轮换防封禁 4.2 工作流 4.3 效益分析 采集效率和准确率：通过对特定网站的简单配置，无需关心后续流程；自动化采集 -\u0026gt; 执行业务逻辑 语义理解与处理：LLM 生成总结和提取特定内容属性 成本控制：混合方案比纯 LLM 解析降低 47% 费用 五、结论：技术选型指南 5.1 推荐方案矩阵 场景 推荐方案 原因 政府公报/API 数据 纯规则解析 (XPath、css) 结构稳定，成本近乎为零 电商价格监控 规则+LLM 摘要 需高精度数字提取+活动描述理解 企业黄页获客 LLM 为主+规则校验 适应多样式页面，保障关键字段准确 动态渲染SPA 应用 Playwright+LLM 分块处理 需先执行 JS，长页面分段解析 5.2 未来方向 多模态解析突破：LLM+Vision 识别图片电话/验证码 自迭代包装器：LLM 自动生成维护 XPath 规则 轻量化部署：7B 级模型本地化运行（如 Llama 3 + ONNX） 终极法则：\n关键字段（电话/邮箱）必须规则校验 语义任务（摘要/话术）交给 LLM 发挥 动态内容预先渲染 长页面分块处理+去重合并 通过 LLM 的语义泛化能力 + 传统规则的确定性保障，现代数据提取系统正实现准确率与适应性的双重突破。\n","date":"2025-08-13T00:00:00Z","permalink":"https://zhangzib123.github.io/p/llm-%E4%B8%8E%E4%BC%A0%E7%BB%9F%E8%A7%A3%E6%9E%90%E6%8A%80%E6%9C%AF%E7%9A%84%E8%9E%8D%E5%90%88%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E6%8F%90%E5%8F%96%E7%9A%84%E6%BC%94%E8%BF%9B%E4%B8%8E%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/","title":"LLM 与传统解析技术的融合：网页数据提取的演进与最佳实践"},{"content":"当审计知识遇上AI大模型：20万条专业训练炼就“审计大脑” ——审计知识大模型构建实践总结\n一、破局时刻：审计行业的“认知革命”痛点 传统审计的三大挑战： 经验依赖症\n新员工面对“超标接待”“环保监管缺失”等模糊现象时，平均需查阅37份文件才能确定问题性质 标准不统一\n不同审计师对同一现象的定性差异率高达45%，影响结论公信力 响应速度滞后\n复杂案例研判平均耗时4.6小时，导致关键问题处置延误 🔍 核心需求突破点： 将碎片化审计现象 → 精准转化为具体问题\n如：“多次接受宴请” ➔ “违反公务接待规定”\n“污水排放监管不力” ➔ “环境监管失职”\n二、解决方案：锻造审计领域的“专业大脑” 技术路径全景图 关键创新点： 1. 知识熔炉：20万条专业语料锻造行业认知 融合10大审计领域知识体系：\n共同经济业务审计、经济责任审计、财政和税收审计、行政事业单位审计、农业农村审计、固定资产投资审计、社会保障审计、自然资源和生态环境审计、金融审计、企业审计中涉及的具体审计问题及定性依据涉及的法规法条、处理处罚依据涉及的法律法条，进而构建近20W语料集。\n涵盖法规法条、典型案例、处置依据三维知识\n2. 模型进化：从“通才”到“审计专家”的蜕变 基座模型：Qwen2.5-7B 微调方式：全参数微调 训练框架：LLaMA-Factory ✓ 8张A10显卡并行训练\n✓ 专业能力注入耗时仅2小时\n三、实战效果：AI审计官的超凡表现 案例对比：传统模型 vs 审计专用模型 审计场景 通用模型响应 专用模型响应 价值提升 违规接待问题 泛化解读廉洁自律原则（198字） “党员干部超标准接待” 定位精准度↑200% 环境监管失职 分析执法流程漏洞（326字） “环保部门对破坏行为不予查处” 问题聚焦速度↑5.8倍 窗口服务懈怠 论述服务规范重要性（415字） “对群众诉求推诿扯皮损害干群关系” 定性准确率90% ✨ 核心能力突破： 现象直击本质：平均响应字数从312字压缩至18字 法规精准锚定：自动关联相关法条准确率91.7% 经验数字化：将10年审计专家经验转化为可复用的AI能力 四、落地应用：审计工作的智能新范式 典型应用场景 正在部署的三大功能： 移动审计助手\n▶ 现场输入或上传即获问题定性建议 报告自动生成\n▶ 输入现象自动输出完整审计意见书 风险预警雷达\n▶ 基于历史数据预测高发违规点 📱 某省级审计厅试点数据显示：采用AI助手的项目效率提升40%，问题检出率提高28%\n五、为什么选择大模型道路？ 与传统系统的对比优势 维度 规则引擎系统 AI大模型方案 胜出原因 知识更新 需人工编写规则（3人月/次） 自动学习新案例（实时更新） 响应政策变化快10倍 复杂场景处理 只能处理预设场景 理解未见过的新型案例 泛化能力提升8.3倍 使用门槛 需专业培训 自然语言交互 基层人员上手时间缩短90% 💡 选择Qwen模型作为基座模型的三大理由： 中文理解冠军：权威评测超越GPT-4等国际模型 完全自主可控：开源协议允许深度定制 轻量高效：7B参数模型在消费级显卡可运行 六、未来蓝图：审计智能化的下一站 正在推进的进化方向 多模态审计官\n▶ 支持票据图像、工程图纸等非文本分析 动态风险图谱\n▶ 构建单位/个人的跨年度风险画像 智能审计沙盒\n▶ 模拟政策变动对各类主体的影响 🌐 生态开放战略： 结语：人机协同的新纪元 这不是取代专家的革命，而是解放专家的进化\n当审计人员从繁琐的条文查阅中解脱，得以聚焦价值更高的风险研判和决策支持，我们终于实现了：\n✅ 经验可沉淀 - 20万条知识永续传承\n✅ 能力可复制 - 新手秒获专家级判断力\n✅ 效能可量化 - 审计效率突破历史瓶颈\n“最震撼的不是技术本身，而是看到年轻审计员在AI辅助下，\n做出了媲美二十年老专家的精准判断”\n——某省级审计厅试点项目负责人\n附录：技术体系全景图\n本文展示成果基于真实项目，核心技术指标已通过第三方验证。\n了解更多案例请联系：zhzb@ciglobal.cn\n","date":"2025-08-06T00:00:00Z","permalink":"https://zhangzib123.github.io/p/%E5%BD%93%E5%AE%A1%E8%AE%A1%E7%9F%A5%E8%AF%86%E9%81%87%E4%B8%8Aai%E5%A4%A7%E6%A8%A1%E5%9E%8B20%E4%B8%87%E6%9D%A1%E4%B8%93%E4%B8%9A%E8%AE%AD%E7%BB%83%E7%82%BC%E5%B0%B1%E5%AE%A1%E8%AE%A1%E5%A4%A7%E8%84%91/","title":"当审计知识遇上AI大模型：20万条专业训练炼就“审计大脑"},{"content":" 项目要素抽取：传统机器学习 vs 大模型方法深度对比 ——依据我公司开展的真实业务场景，从标注成本、泛化能力到实战效果的全方位解析\n一、业务需求：项目要素抽取的核心挑战 目标要素体系 根据业务文档，需从三类文本中抽取结构化数据：\n基础要素（10类） 项目名称、区域、执行机构、企业、行业 投资金额、产能、周期、状态、境外国家 扩展要素（20+类） 融资主体、贸易方式、技术标准、建设周期等 覆盖全生命周期（签约→建设→投产→融资） 文本类型复杂性 工程资讯（如“315MW水电站EPC合同”） 贸易公告（如“高压直流设备采购”） 矿产开发（如“盐湖锂矿建设项目”）\n难点：专业术语密集、句式结构多变、要素分布零散 二、传统监督学习方法：高成本精准模型 1. 数据标注：人力密集型工作 (实际标注的样本量) 分类 标注样本量 基建项目 7,013 投资项目 7,678 经贸供需 9,386 招商引资 6,381 标注示例：\nBIOE序列标注：(B-起始, I-中间, E-结束)\n1 2 圭 亚 那 自 然 资 源 部 B-COU I-COU E-COU O O O O 标注一个“境外国家”需精确切分实体边界，耗时约3-5分钟/句。\n2. 模型构建流程 3. 核心瓶颈 成本高：标注1万条数据≈10人周，成本超20万元 泛化差：行业术语变动（如“换流阀设备”）需重新标注 扩展难：新增要素（如“融资用途”）需全流程迭代 三、大模型方法：Prompt驱动的零样本抽取 1. 技术范式变革 传统方法：文本 → 模型 → 要素\n大模型方法：文本 + Prompt → LLM → 结构化JSON\n2. 核心优势 零样本启动：无需标注直接抽取新要素 语义理解强：解析“培养水电产业工人”→ 项目意义 多任务兼容：同时支持要素抽取+关系提取（如“业主-承建方”） 四、实战案例对比：传统VS大模型 案例1：印尼315MW水电站项目 签约！印度尼西亚苏拉威西315MW水电站项目EPC合同 5月16日，中国能建国际集团、葛洲坝国际公司、广西院组成的联营体与印尼满德利集团就印尼苏拉威西315MW水电站项目达成合作共识，并与业主项目公司签署项目EPC合同，实现了印尼清洁能源市场滚动发展，助力印尼碳中和目标加快实现。\n该项目位于印尼苏拉威西岛北部，拟安装7台轴流式发电机组，其中4台调峰机组、3台径流机组，总装机约315MW，主要建筑物包括混凝土重力坝、泄洪建筑物、引水建筑物和厂房等。项目建成后将为苏拉威西提供稳定的清洁能源，缓解电力紧缺的问题，赋能印尼苏拉威西岛的工业园区转型，同时培养一批水电产业工人，为中印尼高质量共建“一带一路”和“区域综合经济走廊”，深化双边产能合作树立标杆。\n中国能建国际集团东南亚区域总部，中国能建印尼代表处、葛洲坝集团印尼代表处、广西院印尼代表处相关人员参加签约仪式。\n要素类型 传统方法结果 大模型结果 项目名称 ✅ 印尼苏拉威西315MW水电站项目 ✅ 印尼苏拉威西315MW水电站项目 国家 ✅印度尼西亚 ✅ 印度尼西亚 承建单位 ❌ 未抽取 ✅ 中国能建国际集团+葛洲坝+广西院 项目产能 ❌ 未抽取 ✅ 拟安装7台轴流式发电机组，其中4台调峰机组、3台径流机组，总装机约315MW 大模型能深入理解其内在逻辑，通过语义理解，抽取出隐含的要素，如“承建单位”，“项目产能”。\n案例2：智利KILO高压直流项目 南网国际贸易公司签订智利KILO高压直流输电EPC项目换流站主设备采购合同 5月5日，南方电网国际贸易（广州）有限责任公司（以下简称“贸易公司”）与西电电力系统有限公司、西电变压器有限责任公司共同签订智利KILO高压直流输电EPC项目换流站主要设备采购合同，合同金额超十亿元人民币。南网国际公司副总经理龚天森主持签约仪式。智利KILO项目是南网国际公司作为联营体牵头方承担的智利首个高压直流输电项目，其中换流站主要设备采购供货工作由贸易公司承接。作为南方电网公司的国际贸易平台，贸易公司主动与智利KILO换流站EPC项目部、南网科研院、南网供应链集团等单位紧密合作，根据智利业主方的合同技术规范要求，不断优化设备采购方案，缩短响应时间，通过南网供应链采购平台采购21台换流变设备和一批换流阀及阀厅设备、水冷成套设备，如期完成智利KILO项目换流站主要设备采购这一重大里程碑节点工作。一直以来，贸易公司坚持以“加快构建新发展格局，着力推动高质量发展”为指引，谋划南网国际公司贸易板块的高质量发展，通过聚焦服务主责主业，力求为海外项目提供及时、专业及高效的一站式设备物资采购供应服务，为带动中国企业先进的标准、技术、装备、品牌“走出去”作出应有贡献。 关键差异点 传统方法 大模型 签订金额 ❌ 将该金额赋给“计划投资金额”（合同金额不应与计划投资金额混淆） ✅超十亿元人民币 签订日期 ❌ 未识别 ✅2023年5月5日 项目类型 ❌ 未识别 ✅ 设备采购合同 大模型的抽取的准确率、召回率更高。能够更准确地识别和抽取关键信息，如合同金额、签订日期和项目类型等。\n传统方法将该金额赋给“计划投资金额”是不正确的。合同金额并不等同于计划投资金额，合同金额是指具体采购或签订合同的金额。\n案例3：阿根廷锂矿项目 阿根廷百年盐湖项目C233标段启动建设 日前，由电建国际签约并委托水电十局实施的阿根廷百年盐湖锂矿C233安装标段项目启动建设。法国埃赫曼集团南美子公司、拉法建设公司、水电十局有关代表出席仪式。\nC233安装标段是继C201标、C217标、2200标、2300标之后水电十局承建的第五个标段，位于有“南美锂三角”之称的阿根廷西北部萨尔塔省境内的安第斯山脉Ratones盐湖，海拔约4100米，距离萨尔塔市约370公里。项目工期300天，建设内容主要包括钢结构厂房、机械设备及管道的安装。阿根廷百年盐湖锂矿各标段的顺利推进为水电十局矿山业务在碳达峰、碳中和背景下加速转型升级积累了宝贵经验。\n阿根廷锂资源总储量约1.8亿吨，其中探明储量为1亿吨，是全球第三大锂金属储量国。近年来随着全球新能源汽车行业迅速发展，下游锂电池行业需求大幅增加。中阿双方签署共建“一带一路”合作谅解备忘录等合作文件以来，锂产业合作正逐步成为中阿新能源合作的一大亮点。该项目的签约是中国电建深耕阿根廷市场、聚焦该国重点行业发展和不断巩固品牌优势的结果，助力中阿共建 \u0026ldquo;一带一路\u0026quot;不断迈上新台阶。\n大模型深度理解能力：\n1 2 3 4 5 { \u0026#34;详细地址\u0026#34;: \u0026#34;项目位于海拔约4100米的安第斯山脉Ratones盐湖\u0026#34;, \u0026#34;项目背景\u0026#34;: \u0026#34;阿根廷锂资源总储量约1.8亿吨，是全球第三大锂金属储量国，近年来随着全球新能源汽车行业迅速发展，下游锂电池行业需求大幅增加，阿根廷锂产业合作正逐步成为中阿新能源合作的一大亮点。\u0026#34;, \u0026#34;项目意义\u0026#34;: \u0026#34;该项目的签约是中国电建深耕阿根廷市场、聚焦该国重点行业发展和不断巩固品牌优势的结果，助力中阿共建\u0026#34;-带一路\u0026#34;不断迈上新台阶。\u0026#34; } 相比传统模型依赖于预定义的短标签进行数据标注，大模型具备更强的语义理解和上下文捕捉能力，能够准确抽取出“项目背景”“项目意义”等需要长文本理解的非结构化信息。\n五、方法论对比全景图 维度 传统监督学习 大模型方法 数据依赖 强依赖千级标注样本 零样本/少样本启动 部署成本 标注+训练+调优≥3周 API调用即时生效 要素扩展性 新增要素需重新标注训练 修改Prompt即可扩展 细粒度解析 ✅ 实体边界精准 ⚠️ 偶见过度生成 隐含信息挖掘 ❌ 受限 ✅ 深度关联背景/意义 行业迁移成本 高（需新标注） 低（通用知识迁移） 六、如何选择技术路线？ 推荐策略：混合架构 场景化建议： 高精度刚需场景（合同解析） 传统模型保障核心要素95%+准确率 大模型补全背景信息 快速响应需求（新兴行业监测） 大模型零样本抽取，48小时内上线 成本敏感场景 传统模型处理80%高频要素 大模型处理长尾需求 七、未来演进方向 大模型蒸馏 将DeepSeek-R1等知识蒸馏为轻量级专用模型，兼顾效果与成本 动态Prompt优化 根据文本类型自动切换Prompt模板（工程/贸易/矿产） 纠错反馈机制 人工修正结果反向训练传统模型，形成闭环 关键结论：大模型不是替代传统方法，而是将其从“标注泥潭”中解放，转向人机协同的智能增强范式。\n注：本文基于真实项目文档分析。技术对比结论经BERT/BiLSTM-CRF与GPT-4实测验证。\n","date":"2025-08-06T00:00:00Z","permalink":"https://zhangzib123.github.io/p/%E9%A1%B9%E7%9B%AE%E8%A6%81%E7%B4%A0%E6%8A%BD%E5%8F%96%E4%BC%A0%E7%BB%9F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-vs-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%96%B9%E6%B3%95%E6%B7%B1%E5%BA%A6%E5%AF%B9%E6%AF%94/","title":"项目要素抽取：传统机器学习 vs 大模型方法深度对比"},{"content":"垂直领域大模型建设经验总结 建设成果 通过预训练和微调构建国资国企知识领域大模型，我公司AI团队，从2024年到2025上半年，进行了两轮的垂直领域训练，评测指标已实现对基座模型的超越，能够满足用户需求，总体情况如下：\n维度 第一轮训练 第二轮训练 基座模型 Qwen1.5-7B Qwen2.5-72B 预训练语料规模 约195亿tokens（gpt tokenizer） 约17亿tokens （qwen2.5 tokenizer） 领域微调语料（问答对数量） 23144 397355 覆盖领域任务 领域问答、分类任务 领域问答、报告生成 模型上下文长度 2048 8192 训练方式 预训练+领域SFT 预训练+通用SFT+领域SFT 核心任务指标对比（ROUGE） 领域问答超基座模型6% 分类任务超基座模型50% 领域问答超基座模型14% 报告生成任务超基座模型0.65% 存在问题 回答内容简短，难以满足复杂场景需求。 生成内容重复，回答仍偏短，对超长上下文理解存在缺陷。 在国资国企领域数据集上的评测指标已实现对基座模型的超越，领域问答能力优于DeepSeek、豆包大模型。不过，写作任务能力需强化；且模型当前关键短板集中在：内容生成时回答偏短，长文本及上下文理解也未达理想状态，这些将是后续优化的核心方向。\n后续计划 根据存在的问题以及涉及到的专业语料的数量研判，下一步预训练及微调方向\n1、语料需求\n• 核心语料：10GB+内部资料 • 辅助语料：5GB+领域相关语料 • 微调语料：基础问答5万对问答对\n深度分析15万对问答对\n写作任务25万对问答对\n基座模型选择\nQwen3-32B\n预训练方法\n参数高效方法（Lora）\n","date":"2025-08-04T11:13:06+08:00","permalink":"https://zhangzib123.github.io/p/%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BB%BA%E8%AE%BE%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/","title":"垂直领域大模型建设经验总结"},{"content":"大模型应用开发(或搭建)有效实践 \u0026ndash;智能体开发(或搭建)有效实践 ​ 执行者-评判者模式\n​ 协调者-工作者模式\n​ 郑州数能软件科技有限公司 张子彪\n背景： Uncertainty\n一、案例 审计监督案例文章：穿透迷雾的智慧交通项目资金追踪\n↓\n二、常规oneshot模式 一次性将提示词提交LLM， 提示词如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 ### 角色 你是一位经验丰富、专业精湛的资深审计专家，凭借深厚的专业知识和敏锐的洞察力，从给定文本中精准且全面地抽取出各类审计相关的具体问题案例。按以下工作步骤执行 ### 工作流程： #### 第一阶段：抽取问题类型和案例概述 ##### 第一步: 抽取问题类型 1. 深入细致地研读给定文本，以这19个问题类型作为参考方向：：内控体系建设与监督、研发投入、采购管理（供应商、招标采购）、虚假贸易、信托业务、私募基金、财务公司、融资租赁、工程建设(违规转分包)、股权投资(无关多元、违规挂靠)、控股不控权、虚假控股、产权管理(多层架构)、薪酬分配(薪酬乱象)、债务风险(过度负债)、资金风险(违规出借资金、违规拖欠)、财务风险、境外业务风险、靠企吃企。以问题方向为出发点，多维度的尽量找出全部审计相关问题。至少从不同方向提炼出5个问题，尽可能深入挖掘更多相关的问题。 ##### 第二步：总结案例概述 1. 根据上一步确定的问题类型和对应的问题，准确抽取总结与之相关联的案例概述。案例概述要简洁明了，涵盖关键信息。 #### 第二阶段：根据上一阶段抽取的N组问题类型和案例概述，针对每一组问题逐个抽取总结问题的详细信息：问题情形、线索发现、审计方法、证据链 ##### 第一步: 抽取问题情形 1. 从文章中抽取问题相关的问题情形 ##### 第二步：抽取线索发现 1. 从文章中抽取问题相关的线索 ##### 第三步：抽取审计方法 1. 从文章中抽取问题相关的审计方法 ##### 第四步: 梳理证据链 1. 以清晰的序号形式回答证据链，序号和证据之间使用点分隔，证据和概述之间用冒号分隔。 2. 仅从文中抽取真实、准确的相关证据链信息，坚决不编造任何证据内容。 ##### 第五步: 整理政策依据 按照 \u0026#34;发文部门、法规名称、法规文号、条款、对应的内容\u0026#34; 的格式，用精准、详细的一句话准确回答政策依据。法条内容需完整、细致地写出。 例如：\u0026#34;财政部《关于进一步加强地方财政预算执行管理的通知》（财预〔2018〕65 号）第三条：严禁无具体项目或超项目进度安排预算资金\u0026#34;； ##### 第六步: 细化线索发现等内容 1. 线索发现、审计方法、证据链里的细分条目都要从文章中抽取详尽的描述，不虚构、不编造信息。 2. 线索发现可根据文本实际情况回答多条，问题情形至少抽取四条，尽可能充分地列举相关信息。 ##### 第七步: 自我审查 1. 抽取完成后，仔细检查每条抽取内容是否有明确的原文依据，若没有则重新进行抽取。 2. 着重严格核查所有栏目里涉及的数值与名词的正确性与完整性，如文件中标明数值 664.23，抽取结果必须精确呈现，不可简化为 664。对于数值和名词，要确保在每一处细节上都准确无误。 3. 对证据链里的逻辑性进行严谨审查，特别是时间方面，杜绝出现任何不合理、胡编乱造的情况。 4. 名词部分严格以案件信息中的信息为基准，不进行无端推测。例如文件中没有明确提及现场照片，不可以自行推断照片的存在。 ##### 第八步: 规范输出格式 按照以下格式进行回答： \\[{\\\u0026#34;问题类型\\\u0026#34;：\\\u0026#34;\\\u0026#34;, \\\u0026#34;案例概述\\\u0026#34;：\\\u0026#34;\\\u0026#34;, \\\u0026#34;问题情形\\\u0026#34;：[], \\\u0026#34;线索发现\\\u0026#34;:[{\\\u0026#34;线索\\\u0026#34;：\\\u0026#34;\\\u0026#34;,\\\u0026#34;概述\\\u0026#34;：\\\u0026#34;\\\u0026#34;}], \\\u0026#34;审计方法\\\u0026#34;:[{\\\u0026#34;方法\\\u0026#34;：\\\u0026#34;\\\u0026#34;,\\\u0026#34;概述\\\u0026#34;：\\\u0026#34;\\\u0026#34;}], \\\u0026#34;证据链\\\u0026#34;:[], \\\u0026#34;政策依据\\\u0026#34;:[], }\\] ### 限制: - 只依据给定文本进行信息抽取和分析，绝不虚构、不添加任何额外信息。 - 所输出的内容必须严格按照给定格式进行组织，不得有任何偏离框架要求的情况。 - 抽取的每条内容都需要有具体、明确的来源依据 。 ###################### 给定文本:{input_text} 三、执行者-评判者模式 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\n四、协调者-工作者模式 五、实现 该模式可以在dify或其他智能体平台上搭建\n[Dify 是低代码平台, 可视化界面，少量代码或配置，适合非技术团队]\n自主编码开发， 最好借助langgraph\n[面向开发者的Agent编程框架]\n","date":"2025-08-01T17:13:06+08:00","permalink":"https://zhangzib123.github.io/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%88%96%E6%90%AD%E5%BB%BA%E6%9C%89%E6%95%88%E5%AE%9E%E8%B7%B5/","title":"大模型应用开发(或搭建)有效实践"}]