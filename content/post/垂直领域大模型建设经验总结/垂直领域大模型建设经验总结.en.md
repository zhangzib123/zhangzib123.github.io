+++
date = '2025-08-04T11:13:06+08:00'
draft = false
title = '垂直领域大模型建设经验总结'
description = "通过预训练和微调构建国资国企知识领域大模型，我公司AI团队，从2024年到2025上半年，进行了两轮的垂直领域训练，评测指标已实现对基座模型的超越，能够满足用户需求 "
categories = [
    "垂直领域大模型建设",
]
tags = [
    "国企知识领域大模型",
    "垂直领域大模型建设",
    "垂直领域大模型预训练",
    "行业大模型微调"
]

+++

## 垂直领域大模型建设经验总结

### 建设成果

通过预训练和微调构建国资国企知识领域大模型，我公司AI团队，从2024年到2025上半年，进行了两轮的垂直领域训练，评测指标已实现对基座模型的超越，能够满足用户需求，总体情况如下：

| 维度                       | 第一轮训练                                 | 第二轮训练                                           |
| -------------------------- | ------------------------------------------ | ---------------------------------------------------- |
| 基座模型                   | Qwen1.5-7B                                 | Qwen2.5-72B                                          |
| 预训练语料规模             | 约195亿tokens（gpt tokenizer）             | 约17亿tokens （qwen2.5 tokenizer）                   |
| 领域微调语料（问答对数量） | 23144                                      | 397355                                               |
| 覆盖领域任务               | 领域问答、分类任务                         | 领域问答、报告生成                                   |
| 模型上下文长度             | 2048                                       | 8192                                                 |
| 训练方式                   | 预训练+领域SFT                             | 预训练+通用SFT+领域SFT                               |
| 核心任务指标对比（ROUGE）  | 领域问答超基座模型6% 分类任务超基座模型50% | 领域问答超基座模型14% 报告生成任务超基座模型0.65%    |
| 存在问题                   | 回答内容简短，难以满足复杂场景需求。       | 生成内容重复，回答仍偏短，对超长上下文理解存在缺陷。 |

在国资国企领域数据集上的评测指标已实现对基座模型的超越，领域问答能力优于DeepSeek、豆包大模型。不过，写作任务能力需强化；且模型当前关键短板集中在：内容生成时回答偏短，长文本及上下文理解也未达理想状态，这些将是后续优化的核心方向。

### 后续计划

**根据存在的问题以及涉及到的专业语料的数量研判，下一步预训练及微调方向**

1、语料需求

• 核心语料：10GB+内部资料
• 辅助语料：5GB+领域相关语料
• 微调语料：基础问答5万对问答对

深度分析15万对问答对

写作任务25万对问答对

2.  基座模型选择

    Qwen3-32B

3.  预训练方法

    参数高效方法（Lora）
