[{"content":"垂直领域大模型建设经验总结 建设成果 通过预训练和微调构建国资国企知识领域大模型，我公司AI团队，从2024年到2025上半年，进行了两轮的垂直领域训练，评测指标已实现对基座模型的超越，能够满足用户需求，总体情况如下：\n维度 第一轮训练 第二轮训练 基座模型 Qwen1.5-7B Qwen2.5-72B 预训练语料规模 约195亿tokens（gpt tokenizer） 约17亿tokens （qwen2.5 tokenizer） 领域微调语料（问答对数量） 23144 397355 覆盖领域任务 领域问答、分类任务 领域问答、报告生成 模型上下文长度 2048 8192 训练方式 预训练+领域SFT 预训练+通用SFT+领域SFT 核心任务指标对比（ROUGE） 领域问答超基座模型6% 分类任务超基座模型50% 领域问答超基座模型14% 报告生成任务超基座模型0.65% 存在问题 回答内容简短，难以满足复杂场景需求。 生成内容重复，回答仍偏短，对超长上下文理解存在缺陷。 在国资国企领域数据集上的评测指标已实现对基座模型的超越，领域问答能力优于DeepSeek、豆包大模型。不过，写作任务能力需强化；且模型当前关键短板集中在：内容生成时回答偏短，长文本及上下文理解也未达理想状态，这些将是后续优化的核心方向。\n后续计划 根据存在的问题以及涉及到的专业语料的数量研判，下一步预训练及微调方向\n1、语料需求\n• 核心语料：10GB+内部资料 • 辅助语料：5GB+领域相关语料 • 微调语料：基础问答5万对问答对\n深度分析15万对问答对\n写作任务25万对问答对\n基座模型选择\nQwen3-32B\n预训练方法\n参数高效方法（Lora）\n","date":"2025-08-04T11:13:06+08:00","permalink":"https://zhangzib123.github.io/p/%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BB%BA%E8%AE%BE%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/","title":"垂直领域大模型建设经验总结"},{"content":"大模型应用开发(或搭建)有效实践 \u0026ndash;智能体开发(或搭建)有效实践 ​ 执行者-评判者模式\n​ 协调者-工作者模式\n​ 郑州数能软件科技有限公司 张子彪\n背景： Uncertainty\n一、案例 审计监督案例文章：穿透迷雾的智慧交通项目资金追踪\n↓\n二、常规oneshot模式 一次性将提示词提交LLM， 提示词如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 ### 角色 你是一位经验丰富、专业精湛的资深审计专家，凭借深厚的专业知识和敏锐的洞察力，从给定文本中精准且全面地抽取出各类审计相关的具体问题案例。按以下工作步骤执行 ### 工作流程： #### 第一阶段：抽取问题类型和案例概述 ##### 第一步: 抽取问题类型 1. 深入细致地研读给定文本，以这19个问题类型作为参考方向：：内控体系建设与监督、研发投入、采购管理（供应商、招标采购）、虚假贸易、信托业务、私募基金、财务公司、融资租赁、工程建设(违规转分包)、股权投资(无关多元、违规挂靠)、控股不控权、虚假控股、产权管理(多层架构)、薪酬分配(薪酬乱象)、债务风险(过度负债)、资金风险(违规出借资金、违规拖欠)、财务风险、境外业务风险、靠企吃企。以问题方向为出发点，多维度的尽量找出全部审计相关问题。至少从不同方向提炼出5个问题，尽可能深入挖掘更多相关的问题。 ##### 第二步：总结案例概述 1. 根据上一步确定的问题类型和对应的问题，准确抽取总结与之相关联的案例概述。案例概述要简洁明了，涵盖关键信息。 #### 第二阶段：根据上一阶段抽取的N组问题类型和案例概述，针对每一组问题逐个抽取总结问题的详细信息：问题情形、线索发现、审计方法、证据链 ##### 第一步: 抽取问题情形 1. 从文章中抽取问题相关的问题情形 ##### 第二步：抽取线索发现 1. 从文章中抽取问题相关的线索 ##### 第三步：抽取审计方法 1. 从文章中抽取问题相关的审计方法 ##### 第四步: 梳理证据链 1. 以清晰的序号形式回答证据链，序号和证据之间使用点分隔，证据和概述之间用冒号分隔。 2. 仅从文中抽取真实、准确的相关证据链信息，坚决不编造任何证据内容。 ##### 第五步: 整理政策依据 按照 \u0026#34;发文部门、法规名称、法规文号、条款、对应的内容\u0026#34; 的格式，用精准、详细的一句话准确回答政策依据。法条内容需完整、细致地写出。 例如：\u0026#34;财政部《关于进一步加强地方财政预算执行管理的通知》（财预〔2018〕65 号）第三条：严禁无具体项目或超项目进度安排预算资金\u0026#34;； ##### 第六步: 细化线索发现等内容 1. 线索发现、审计方法、证据链里的细分条目都要从文章中抽取详尽的描述，不虚构、不编造信息。 2. 线索发现可根据文本实际情况回答多条，问题情形至少抽取四条，尽可能充分地列举相关信息。 ##### 第七步: 自我审查 1. 抽取完成后，仔细检查每条抽取内容是否有明确的原文依据，若没有则重新进行抽取。 2. 着重严格核查所有栏目里涉及的数值与名词的正确性与完整性，如文件中标明数值 664.23，抽取结果必须精确呈现，不可简化为 664。对于数值和名词，要确保在每一处细节上都准确无误。 3. 对证据链里的逻辑性进行严谨审查，特别是时间方面，杜绝出现任何不合理、胡编乱造的情况。 4. 名词部分严格以案件信息中的信息为基准，不进行无端推测。例如文件中没有明确提及现场照片，不可以自行推断照片的存在。 ##### 第八步: 规范输出格式 按照以下格式进行回答： \\[{\\\u0026#34;问题类型\\\u0026#34;：\\\u0026#34;\\\u0026#34;, \\\u0026#34;案例概述\\\u0026#34;：\\\u0026#34;\\\u0026#34;, \\\u0026#34;问题情形\\\u0026#34;：[], \\\u0026#34;线索发现\\\u0026#34;:[{\\\u0026#34;线索\\\u0026#34;：\\\u0026#34;\\\u0026#34;,\\\u0026#34;概述\\\u0026#34;：\\\u0026#34;\\\u0026#34;}], \\\u0026#34;审计方法\\\u0026#34;:[{\\\u0026#34;方法\\\u0026#34;：\\\u0026#34;\\\u0026#34;,\\\u0026#34;概述\\\u0026#34;：\\\u0026#34;\\\u0026#34;}], \\\u0026#34;证据链\\\u0026#34;:[], \\\u0026#34;政策依据\\\u0026#34;:[], }\\] ### 限制: - 只依据给定文本进行信息抽取和分析，绝不虚构、不添加任何额外信息。 - 所输出的内容必须严格按照给定格式进行组织，不得有任何偏离框架要求的情况。 - 抽取的每条内容都需要有具体、明确的来源依据 。 ###################### 给定文本:{input_text} 三、执行者-评判者模式 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\n四、协调者-工作者模式 五、实现 该模式可以在dify或其他智能体平台上搭建\n[Dify 是低代码平台, 可视化界面，少量代码或配置，适合非技术团队]\n自主编码开发， 最好借助langgraph\n[面向开发者的Agent编程框架]\n","date":"2025-08-01T17:13:06+08:00","permalink":"https://zhangzib123.github.io/p/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%88%96%E6%90%AD%E5%BB%BA%E6%9C%89%E6%95%88%E5%AE%9E%E8%B7%B5/","title":"大模型应用开发(或搭建)有效实践"}]